{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "import missingno as msno\n",
    "from icecream import ic\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "%load_ext blackcellmagic\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(config[\"paths\"][\"ptb_train\"], header=None)\n",
    "test_df = pd.read_csv(config[\"paths\"][\"ptb_test\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = train_df.iloc[:, :-1].to_numpy()\n",
    "y_train_full = train_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "X_test = test_df.iloc[:, :-1].to_numpy()\n",
    "y_test = test_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "X_train_full = np.c_[X_train_full, np.zeros((X_train_full.shape[0], 3))]\n",
    "X_test = np.c_[X_test, np.zeros((X_test.shape[0], 3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"preprocessing\"][\"use_smote\"]:\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    #ic(X_train.shape, y_train.shape)\n",
    "    #ic(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTB_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ATTENTION\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.0):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = int(d_model // h)\n",
    "        self.h = int(h)\n",
    "        self.linears = clones(nn.Linear(d_model, d_model, dtype=torch.float32), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1) # Same mask applied to all h heads.\n",
    "            \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(-1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears[:3], [query, key, value])\n",
    "        ]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (x.transpose(1, 2).contiguous().view( -1, self.h * self.d_k))\n",
    "        \n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        out = self.linears[-1](x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BLOCKING\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module.\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features).to(DEVICE))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features).to(DEVICE))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(f'Layer Norm input type = {x.dtype}')\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "        #print(f'Layer Norm result type = {result.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"A residual connection followed by a layer norm.\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        ic(x.shape)\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        ic(x.shape)\n",
    "        x = self.sublayer[1](x, self.feed_forward)\n",
    "        ic(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"Construct a FeedForward network with one hidden layer\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff, dtype=torch.float32)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(d_ff, d_model, dtype=torch.float32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"Transformer Model\"\n",
    "    def __init__(self, input_size, num_classes, num_heads=8, N=6, d_ff=256, dropout=0.0):\n",
    "        super().__init__()\n",
    "        c = copy.deepcopy\n",
    "        attn = MultiHeadedAttention(num_heads, input_size)\n",
    "        ff = FeedForward(input_size, d_ff, dropout)\n",
    "        self.encoder = Encoder(EncoderBlock(input_size, c(attn), c(ff), dropout), N)\n",
    "        self.fc = nn.Linear(input_size, num_classes, dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        ic(x.shape)\n",
    "        x = self.fc(x)\n",
    "        ic(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience, verbose = 0, mode = 'mim'):\n",
    "        self.patience = patience\n",
    "        self.best_metric = float('inf') if mode == 'min' else 0.0\n",
    "        self.best_epoch = -1\n",
    "        self.early_stop = False\n",
    "        self.verbose = verbose\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, val_metric, epoch_index):\n",
    "        if self.mode == 'max' and val_metric >= self.best_metric or self.mode == 'min' and val_metric <= self.best_metric:\n",
    "            self.early_stop = False\n",
    "            self.best_metric = val_metric\n",
    "            self.best_epoch = epoch_index\n",
    "        else:\n",
    "            self.early_stop = (epoch_index - self.best_epoch) >= self.patience\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping: current epoch {epoch_index + 1} no improvement for metric, best metric = {self.best_metric:0.4f} in epoch = {self.best_epoch + 1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    PTB_Dataset(X_train, y_train), batch_size=config[\"dataloader\"][\"train_batch_size\"], shuffle=True, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    PTB_Dataset(X_val, y_val), batch_size=config[\"dataloader\"][\"val_batch_size\"], shuffle=False, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    PTB_Dataset(X_test, y_test), batch_size=config[\"dataloader\"][\"test_batch_size\"], shuffle=False, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, epoch_index):\n",
    "    \n",
    "    model.train(True) #just in case - decided to switch model to train mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "    batches_total = len(train_loader) #returns number of batches\n",
    "    y_preds = np.array([])\n",
    "    y_true = np.array([])\n",
    "    \n",
    "    #displaying pretty progress bar for each epoch\n",
    "    #with tqdm(desc=f\"train epoch {epoch_index}:\", leave=False, total=batches_total) as pbar_train:\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.type(torch.LongTensor).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            preds = torch.argmax(F.softmax(outputs,1), 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            processed_data += inputs.size(0)\n",
    "            y_preds = np.concatenate((y_preds, preds.cpu().numpy()))\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()))\n",
    "            \n",
    "            zero_grad_count = 0\n",
    "            total_grad_count = 0\n",
    "        #     for param in model.parameters():\n",
    "        #         if param.grad is not None:\n",
    "        #                 zero_grad_count += torch.sum(param.grad == 0).item()\n",
    "        #                 total_grad_count += torch.numel(param.grad)\n",
    "\n",
    "        #     print(f\"Number of zero gradients = {zero_grad_count} / {total_grad_count}\")\n",
    "                \n",
    "            #pbar_train.update(1)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    train_f1 = f1_score(y_true, y_preds)\n",
    "    return train_loss, train_acc, train_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_epoch(model, val_loader, criterion, epoch_index):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "    y_preds = np.array([])\n",
    "    y_true = np.array([])\n",
    "\n",
    "    #displaying pretty progress bar for each epoch\n",
    "    #with tqdm(desc=f\"eval epoch {epoch_index}:\", leave=False, total=len(val_loader)) as pbar_val:\n",
    "            \n",
    "    for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = torch.argmax(F.softmax(outputs, 1), 1)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            processed_size += inputs.size(0)\n",
    "            y_preds = np.concatenate((y_preds, preds.cpu().numpy()))\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()))\n",
    "            #pbar_val.update(1)\n",
    "    \n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.cpu().numpy() / processed_size\n",
    "    val_f1 = f1_score(y_true, y_preds)\n",
    "    return val_loss, val_acc, val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, val_loader, model, epochs, \\\n",
    "          criterion, opt, scheduler = None, early_stopping: EarlyStopping = None):\n",
    "    \n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f}, val_acc {v_acc:0.4f}, \\\n",
    "    train_f1 {train_f1:0.4f}, val_f1 {val_f1:0.4f} \\\n",
    "    best_val_f1 = {best_val_f1:0.4f}\"\n",
    "\n",
    "    # adding storage for best weights, will be finally used \n",
    "    # when training for all epochs is finished\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            train_loss, train_acc, train_f1 = fit_epoch(model, train_loader, criterion, opt, epoch)\n",
    "            \n",
    "            val_loss, val_acc, val_f1 = eval_epoch(model, val_loader, criterion, epoch)\n",
    "            history.append((train_loss, train_acc, train_f1, val_loss, val_acc, val_f1))\n",
    "            \n",
    "            #remember model weights if current accuracy is better than \"best_acc\"\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, \\\n",
    "                                           train_f1 = train_f1, v_acc=val_acc, \\\n",
    "                                           val_f1 = val_f1, best_val_f1 = best_f1))\n",
    "            \n",
    "             # if scheduler is defined, do LR step after every epoch\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "            \n",
    "            if early_stopping is not None:\n",
    "                early_stopping(val_f1, epoch)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(f'Early stopping, epoch = {epoch + 1}, best VAL F1 = {best_f1:0.4f}')\n",
    "                    break\n",
    "            \n",
    "    # finally - let's load the best model weights\n",
    "    model.load_state_dict(best_model_wts)        \n",
    "            \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "        true_labels = []\n",
    "    \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "    return probs, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_parameters(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = X_train.shape[1]\n",
    "N_CLASSES = len(np.unique(y_train))\n",
    "DROPOUT = 0.3\n",
    "LR = 5e-03\n",
    "N_EPOCHS = 100\n",
    "HUM_HEADS = 5\n",
    "NUM_ENCODERS = 5\n",
    "DIM_FF = 128\n",
    "\n",
    "model_t = Transformer(INPUT_SIZE, N_CLASSES, HUM_HEADS, NUM_ENCODERS, d_ff = DIM_FF, dropout = DROPOUT)\n",
    "#init_parameters(model_t)\n",
    "\n",
    "model_t = model_t.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model_t.parameters(), lr=LR)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, threshold=1e-05, verbose = 1)\n",
    "early_stopping = EarlyStopping(patience = 10, verbose = 1, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/100 [00:00<?, ?it/s]ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "/tmp/ipykernel_53046/3330561303.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.argmax(F.softmax(outputs), 1)\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 2])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "ic| x.shape: torch.Size([32, 190])\n",
      "epoch:   0%|          | 0/100 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_t, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, model, epochs, criterion, opt, scheduler, early_stopping)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mepochs) \u001b[38;5;28;01mas\u001b[39;00m pbar_outer:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 19\u001b[0m         train_loss, train_acc, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mfit_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         val_loss, val_acc, val_f1 \u001b[38;5;241m=\u001b[39m eval_epoch(model, val_loader, criterion, epoch)\n\u001b[1;32m     22\u001b[0m         history\u001b[38;5;241m.\u001b[39mappend((train_loss, train_acc, train_f1, val_loss, val_acc, val_f1))\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36mfit_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, epoch_index)\u001b[0m\n\u001b[1;32m     18\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m     15\u001b[0m     ic(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/icecream/icecream.py:212\u001b[0m, in \u001b[0;36mIceCreamDebugger.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    210\u001b[0m         prefix \u001b[38;5;241m=\u001b[39m callOrValue(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix)\n\u001b[1;32m    211\u001b[0m         out \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m err\u001b[38;5;241m.\u001b[39minfoMessage\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:  \u001b[38;5;66;03m# E.g. ic().\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     passthrough \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/icecream/icecream.py:83\u001b[0m, in \u001b[0;36mcolorizedStderrPrint\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     81\u001b[0m colored \u001b[38;5;241m=\u001b[39m colorize(s)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m supportTerminalColorsInWindows():\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mstderrPrint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolored\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/icecream/icecream.py:69\u001b[0m, in \u001b[0;36mstderrPrint\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstderrPrint\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstderr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/colorama/ansitowin32.py:47\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/colorama/ansitowin32.py:177\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mwrite(text)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/colorama/ansitowin32.py:202\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mANSI_CSI_RE\u001b[38;5;241m.\u001b[39mfinditer(text):\n\u001b[1;32m    201\u001b[0m     start, end \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mspan()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_ansi(\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mgroups())\n\u001b[1;32m    204\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/colorama/ansitowin32.py:211\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[0;34m(self, text, start, end)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mwrite(text[start:end])\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/iostream.py:609\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_t, history = train(train_loader, val_loader, model_t, N_EPOCHS,\\\n",
    "                         criterion, optimizer, scheduler, early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3397256814387403, Test accuracy: 0.9725180350395053, Test F1: 0.9809342230695901\n"
     ]
    }
   ],
   "source": [
    "# testing the model and returning key metrics\n",
    "probs, y_test = predict(model_t, test_loader)\n",
    "y_pred = np.argmax(probs, axis=1)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "test_acc = np.mean(y_test == y_pred)\n",
    "test_loss = criterion(torch.tensor(probs), torch.tensor(y_test)).item()\n",
    "\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_acc}, Test F1: {test_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss: 0.34013988103442655, Test accuracy: 0.9728615596015115, Test F1: 0.9810959559703278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_heads, num_encoders, dim_feedforward, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, dim_feedforward)\n",
    "        self.positional_encoding = PositionalEncoding(dim_feedforward, dropout)\n",
    "\n",
    "        # Custom encoder layer to extract attention\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoderLayerWithAttention(dim_feedforward, num_heads, dropout)\n",
    "            for _ in range(num_encoders)\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Linear(dim_feedforward, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        attentions = []\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            x, attn = layer(x)\n",
    "            attentions.append(attn)\n",
    "        \n",
    "        x = x.mean(dim=1)\n",
    "        x = self.output_layer(x)\n",
    "        return x#, attentions\n",
    "\n",
    "class TransformerEncoderLayerWithAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_model, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src2, attn = self.self_attn(src, src, src, need_weights=True)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.dropout(self.linear1(F.relu(self.linear2(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq, pad_token=0):\n",
    "    # Assuming `seq` is of shape [batch_size, sequence_length]\n",
    "    # and padded positions are denoted by `pad_token` (e.g., 0)\n",
    "    mask = (seq != pad_token)  # Shape: [batch_size, 1, 1, sequence_length]\n",
    "    # `True` for non-pad tokens and `False` for pad tokens\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, model_size, num_classes, num_heads=8, num_layers=6, d_ff=256, dropout=0.1\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, input_size * model_size)\n",
    "        #self.pos_encoder = PositionalEncoding(model_size, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_size, nhead=num_heads, dim_feedforward = d_ff, \n",
    "            dropout=dropout, activation='gelu', layer_norm_eps=1e-6\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layers, num_layers=num_layers,\n",
    "            norm = nn.LayerNorm(model_size)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(2 * model_size, num_classes)\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        src = self.embedding(x) * math.sqrt(self.input_size)\n",
    "        src = src.reshape(x.shape[0], x.shape[1], -1)\n",
    "        #ic(src.shape)\n",
    "        #src = self.pos_encoder(src)\n",
    "        #ic(src.shape)\n",
    "        output = self.transformer_encoder(src)\n",
    "        #ic(output.shape)\n",
    "        #ic(output.mean(dim=1).shape)\n",
    "        # max pooling:\n",
    "        avg_pooled = output.mean(dim=1)\n",
    "        max_pooled = output.max(dim=1).values\n",
    "        output = torch.cat([avg_pooled, max_pooled], dim=1)\n",
    "        output = self.output_layer(output)\n",
    "        #ic(output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = X_train.shape[1]\n",
    "N_CLASSES = len(np.unique(y_train))\n",
    "DROPOUT = 0.2\n",
    "LR = 1e-3\n",
    "N_EPOCHS = 100\n",
    "NUM_HEADS = 5\n",
    "NUM_ENCODERS = 5\n",
    "DIM_FF = 128\n",
    "MODEL_SIZE = 10\n",
    "\n",
    "model_t = TransformerModel(\n",
    "    num_classes=N_CLASSES,\n",
    "    input_size=INPUT_SIZE,\n",
    "    model_size=MODEL_SIZE,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_layers=NUM_ENCODERS,\n",
    "    d_ff=DIM_FF,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "model_t = model_t.to(DEVICE)\n",
    "init_parameters(model_t)\n",
    "\n",
    "optimizer = optim.AdamW(model_t.parameters(), lr=LR, weight_decay = config[\"adamw\"][\"weight_decay\"])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, threshold=1e-05, verbose = 1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "early_stopping = EarlyStopping(patience = 10, verbose = 1, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 0.5561     val_loss 0.4443 train_acc 0.7201, val_acc 0.7935,     train_f1 0.8299, val_f1 0.8589     best_val_f1 = 0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 002 train_loss: 0.4752     val_loss 0.3934 train_acc 0.7529, val_acc 0.8042,     train_f1 0.8380, val_f1 0.8611     best_val_f1 = 0.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 003 train_loss: 0.4267     val_loss 0.4066 train_acc 0.7908, val_acc 0.7978,     train_f1 0.8570, val_f1 0.8556     best_val_f1 = 0.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   3%|▎         | 3/100 [00:06<03:26,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 3 no improvement for metric, best metric = 0.8611 in epoch = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 004 train_loss: 0.4057     val_loss 0.3939 train_acc 0.8035, val_acc 0.8171,     train_f1 0.8639, val_f1 0.8692     best_val_f1 = 0.8692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 005 train_loss: 0.3965     val_loss 0.4373 train_acc 0.8081, val_acc 0.8012,     train_f1 0.8663, val_f1 0.8500     best_val_f1 = 0.8692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   5%|▌         | 5/100 [00:10<03:22,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 5 no improvement for metric, best metric = 0.8692 in epoch = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 006 train_loss: 0.3995     val_loss 0.3986 train_acc 0.8085, val_acc 0.8240,     train_f1 0.8681, val_f1 0.8806     best_val_f1 = 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 007 train_loss: 0.3936     val_loss 0.4132 train_acc 0.8171, val_acc 0.8098,     train_f1 0.8736, val_f1 0.8554     best_val_f1 = 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   7%|▋         | 7/100 [00:14<03:18,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 7 no improvement for metric, best metric = 0.8806 in epoch = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 008 train_loss: 0.3778     val_loss 0.4467 train_acc 0.8204, val_acc 0.8227,     train_f1 0.8746, val_f1 0.8789     best_val_f1 = 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   8%|▊         | 8/100 [00:17<03:16,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 8 no improvement for metric, best metric = 0.8806 in epoch = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 009 train_loss: 0.3597     val_loss 0.3821 train_acc 0.8326, val_acc 0.8308,     train_f1 0.8834, val_f1 0.8798     best_val_f1 = 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   9%|▉         | 9/100 [00:19<03:14,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 9 no improvement for metric, best metric = 0.8806 in epoch = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 010 train_loss: 0.3530     val_loss 0.3405 train_acc 0.8396, val_acc 0.8390,     train_f1 0.8881, val_f1 0.8805     best_val_f1 = 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  10%|█         | 10/100 [00:21<03:13,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 10 no improvement for metric, best metric = 0.8806 in epoch = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 011 train_loss: 0.3351     val_loss 0.3188 train_acc 0.8471, val_acc 0.8639,     train_f1 0.8924, val_f1 0.9045     best_val_f1 = 0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 012 train_loss: 0.3329     val_loss 0.3014 train_acc 0.8457, val_acc 0.8600,     train_f1 0.8919, val_f1 0.9013     best_val_f1 = 0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  12%|█▏        | 12/100 [00:25<03:09,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 12 no improvement for metric, best metric = 0.9045 in epoch = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 013 train_loss: 0.3128     val_loss 0.3071 train_acc 0.8604, val_acc 0.8639,     train_f1 0.9023, val_f1 0.9017     best_val_f1 = 0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  13%|█▎        | 13/100 [00:27<03:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 13 no improvement for metric, best metric = 0.9045 in epoch = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 014 train_loss: 0.2982     val_loss 0.3018 train_acc 0.8677, val_acc 0.8751,     train_f1 0.9069, val_f1 0.9120     best_val_f1 = 0.9120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 015 train_loss: 0.2988     val_loss 0.2760 train_acc 0.8668, val_acc 0.8738,     train_f1 0.9067, val_f1 0.9121     best_val_f1 = 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 016 train_loss: 0.2823     val_loss 0.3122 train_acc 0.8718, val_acc 0.8635,     train_f1 0.9098, val_f1 0.9015     best_val_f1 = 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  16%|█▌        | 16/100 [00:34<03:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 16 no improvement for metric, best metric = 0.9121 in epoch = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 017 train_loss: 0.2773     val_loss 0.3220 train_acc 0.8802, val_acc 0.8600,     train_f1 0.9161, val_f1 0.8957     best_val_f1 = 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  17%|█▋        | 17/100 [00:36<02:57,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 17 no improvement for metric, best metric = 0.9121 in epoch = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 018 train_loss: 0.2639     val_loss 0.2583 train_acc 0.8846, val_acc 0.8866,     train_f1 0.9194, val_f1 0.9211     best_val_f1 = 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 019 train_loss: 0.2537     val_loss 0.2636 train_acc 0.8889, val_acc 0.8849,     train_f1 0.9224, val_f1 0.9170     best_val_f1 = 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  19%|█▉        | 19/100 [00:40<02:53,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 19 no improvement for metric, best metric = 0.9211 in epoch = 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 020 train_loss: 0.2414     val_loss 0.2464 train_acc 0.8995, val_acc 0.8901,     train_f1 0.9302, val_f1 0.9219     best_val_f1 = 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 021 train_loss: 0.2368     val_loss 0.2470 train_acc 0.9021, val_acc 0.8970,     train_f1 0.9320, val_f1 0.9298     best_val_f1 = 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 022 train_loss: 0.2274     val_loss 0.2398 train_acc 0.9054, val_acc 0.9004,     train_f1 0.9341, val_f1 0.9304     best_val_f1 = 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 023 train_loss: 0.2241     val_loss 0.2739 train_acc 0.9079, val_acc 0.8914,     train_f1 0.9360, val_f1 0.9234     best_val_f1 = 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  23%|██▎       | 23/100 [00:49<02:45,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 23 no improvement for metric, best metric = 0.9304 in epoch = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 024 train_loss: 0.2243     val_loss 0.2456 train_acc 0.9075, val_acc 0.9000,     train_f1 0.9358, val_f1 0.9279     best_val_f1 = 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  24%|██▍       | 24/100 [00:51<02:43,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 24 no improvement for metric, best metric = 0.9304 in epoch = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 025 train_loss: 0.2142     val_loss 0.2301 train_acc 0.9123, val_acc 0.9077,     train_f1 0.9391, val_f1 0.9354     best_val_f1 = 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 026 train_loss: 0.2056     val_loss 0.2123 train_acc 0.9165, val_acc 0.9103,     train_f1 0.9418, val_f1 0.9373     best_val_f1 = 0.9373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 027 train_loss: 0.1991     val_loss 0.2356 train_acc 0.9170, val_acc 0.9000,     train_f1 0.9422, val_f1 0.9309     best_val_f1 = 0.9373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  27%|██▋       | 27/100 [00:57<02:36,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 27 no improvement for metric, best metric = 0.9373 in epoch = 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 028 train_loss: 0.1959     val_loss 0.2009 train_acc 0.9192, val_acc 0.9167,     train_f1 0.9439, val_f1 0.9417     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 029 train_loss: 0.1921     val_loss 0.2178 train_acc 0.9205, val_acc 0.9060,     train_f1 0.9449, val_f1 0.9347     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  29%|██▉       | 29/100 [01:02<02:31,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 29 no improvement for metric, best metric = 0.9417 in epoch = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 030 train_loss: 0.1926     val_loss 0.2007 train_acc 0.9218, val_acc 0.9137,     train_f1 0.9456, val_f1 0.9397     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  30%|███       | 30/100 [01:04<02:29,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 30 no improvement for metric, best metric = 0.9417 in epoch = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 031 train_loss: 0.1851     val_loss 0.2021 train_acc 0.9254, val_acc 0.9150,     train_f1 0.9481, val_f1 0.9411     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  31%|███       | 31/100 [01:06<02:27,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 31 no improvement for metric, best metric = 0.9417 in epoch = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 032 train_loss: 0.1844     val_loss 0.1941 train_acc 0.9263, val_acc 0.9154,     train_f1 0.9489, val_f1 0.9411     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  32%|███▏      | 32/100 [01:08<02:25,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 32 no improvement for metric, best metric = 0.9417 in epoch = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 033 train_loss: 0.1862     val_loss 0.2064 train_acc 0.9244, val_acc 0.9073,     train_f1 0.9476, val_f1 0.9359     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  33%|███▎      | 33/100 [01:10<02:23,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 33 no improvement for metric, best metric = 0.9417 in epoch = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 034 train_loss: 0.1800     val_loss 0.2116 train_acc 0.9274, val_acc 0.9163,     train_f1 0.9496, val_f1 0.9401     best_val_f1 = 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  34%|███▍      | 34/100 [01:12<02:21,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 34 no improvement for metric, best metric = 0.9417 in epoch = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 035 train_loss: 0.1775     val_loss 0.1792 train_acc 0.9275, val_acc 0.9231,     train_f1 0.9497, val_f1 0.9464     best_val_f1 = 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 036 train_loss: 0.1698     val_loss 0.2050 train_acc 0.9349, val_acc 0.9197,     train_f1 0.9549, val_f1 0.9439     best_val_f1 = 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  36%|███▌      | 36/100 [01:17<02:16,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 36 no improvement for metric, best metric = 0.9464 in epoch = 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 037 train_loss: 0.1634     val_loss 0.2382 train_acc 0.9350, val_acc 0.9060,     train_f1 0.9550, val_f1 0.9332     best_val_f1 = 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  37%|███▋      | 37/100 [01:19<02:14,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 37 no improvement for metric, best metric = 0.9464 in epoch = 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 038 train_loss: 0.1629     val_loss 0.1894 train_acc 0.9334, val_acc 0.9240,     train_f1 0.9539, val_f1 0.9480     best_val_f1 = 0.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 039 train_loss: 0.1628     val_loss 0.1857 train_acc 0.9366, val_acc 0.9188,     train_f1 0.9561, val_f1 0.9431     best_val_f1 = 0.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  39%|███▉      | 39/100 [01:23<02:09,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 39 no improvement for metric, best metric = 0.9480 in epoch = 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 040 train_loss: 0.1618     val_loss 0.1997 train_acc 0.9334, val_acc 0.9188,     train_f1 0.9539, val_f1 0.9434     best_val_f1 = 0.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|████      | 40/100 [01:25<02:07,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 40 no improvement for metric, best metric = 0.9480 in epoch = 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 041 train_loss: 0.1496     val_loss 0.1826 train_acc 0.9421, val_acc 0.9317,     train_f1 0.9599, val_f1 0.9520     best_val_f1 = 0.9520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 042 train_loss: 0.1508     val_loss 0.1816 train_acc 0.9420, val_acc 0.9304,     train_f1 0.9599, val_f1 0.9519     best_val_f1 = 0.9520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  42%|████▏     | 42/100 [01:29<02:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 42 no improvement for metric, best metric = 0.9520 in epoch = 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 043 train_loss: 0.1444     val_loss 0.2055 train_acc 0.9438, val_acc 0.9240,     train_f1 0.9611, val_f1 0.9458     best_val_f1 = 0.9520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  43%|████▎     | 43/100 [01:31<02:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 43 no improvement for metric, best metric = 0.9520 in epoch = 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 044 train_loss: 0.1420     val_loss 0.1836 train_acc 0.9456, val_acc 0.9330,     train_f1 0.9624, val_f1 0.9532     best_val_f1 = 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 045 train_loss: 0.1416     val_loss 0.1707 train_acc 0.9444, val_acc 0.9360,     train_f1 0.9615, val_f1 0.9555     best_val_f1 = 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 046 train_loss: 0.1524     val_loss 0.1822 train_acc 0.9388, val_acc 0.9270,     train_f1 0.9576, val_f1 0.9499     best_val_f1 = 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  46%|████▌     | 46/100 [01:38<01:53,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 46 no improvement for metric, best metric = 0.9555 in epoch = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 047 train_loss: 0.1266     val_loss 0.1859 train_acc 0.9491, val_acc 0.9334,     train_f1 0.9648, val_f1 0.9544     best_val_f1 = 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  47%|████▋     | 47/100 [01:40<01:52,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 47 no improvement for metric, best metric = 0.9555 in epoch = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 048 train_loss: 0.1395     val_loss 0.1896 train_acc 0.9445, val_acc 0.9283,     train_f1 0.9616, val_f1 0.9504     best_val_f1 = 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  48%|████▊     | 48/100 [01:42<01:50,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 48 no improvement for metric, best metric = 0.9555 in epoch = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 049 train_loss: 0.1241     val_loss 0.2009 train_acc 0.9523, val_acc 0.9253,     train_f1 0.9670, val_f1 0.9494     best_val_f1 = 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  49%|████▉     | 49/100 [01:44<01:48,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 49 no improvement for metric, best metric = 0.9555 in epoch = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 050 train_loss: 0.1230     val_loss 0.1587 train_acc 0.9539, val_acc 0.9450,     train_f1 0.9681, val_f1 0.9618     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 051 train_loss: 0.1199     val_loss 0.1729 train_acc 0.9579, val_acc 0.9369,     train_f1 0.9709, val_f1 0.9559     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  51%|█████     | 51/100 [01:48<01:44,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 51 no improvement for metric, best metric = 0.9618 in epoch = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 052 train_loss: 0.1189     val_loss 0.1618 train_acc 0.9565, val_acc 0.9386,     train_f1 0.9699, val_f1 0.9579     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  52%|█████▏    | 52/100 [01:51<01:42,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 52 no improvement for metric, best metric = 0.9618 in epoch = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 053 train_loss: 0.1182     val_loss 0.1747 train_acc 0.9539, val_acc 0.9386,     train_f1 0.9681, val_f1 0.9579     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  53%|█████▎    | 53/100 [01:53<01:40,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 53 no improvement for metric, best metric = 0.9618 in epoch = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 054 train_loss: 0.1128     val_loss 0.1725 train_acc 0.9569, val_acc 0.9407,     train_f1 0.9702, val_f1 0.9587     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  54%|█████▍    | 54/100 [01:55<01:38,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 54 no improvement for metric, best metric = 0.9618 in epoch = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 055 train_loss: 0.1164     val_loss 0.1740 train_acc 0.9564, val_acc 0.9382,     train_f1 0.9698, val_f1 0.9571     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  55%|█████▌    | 55/100 [01:57<01:36,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 55 no improvement for metric, best metric = 0.9618 in epoch = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 056 train_loss: 0.1044     val_loss 0.2152 train_acc 0.9614, val_acc 0.9317,     train_f1 0.9733, val_f1 0.9523     best_val_f1 = 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  56%|█████▌    | 56/100 [01:59<01:34,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 56 no improvement for metric, best metric = 0.9618 in epoch = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 057 train_loss: 0.1080     val_loss 0.1648 train_acc 0.9587, val_acc 0.9459,     train_f1 0.9714, val_f1 0.9625     best_val_f1 = 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 058 train_loss: 0.0987     val_loss 0.1938 train_acc 0.9645, val_acc 0.9334,     train_f1 0.9754, val_f1 0.9532     best_val_f1 = 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  58%|█████▊    | 58/100 [02:03<01:30,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 58 no improvement for metric, best metric = 0.9625 in epoch = 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 059 train_loss: 0.0979     val_loss 0.1564 train_acc 0.9662, val_acc 0.9433,     train_f1 0.9766, val_f1 0.9614     best_val_f1 = 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  59%|█████▉    | 59/100 [02:06<01:27,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 59 no improvement for metric, best metric = 0.9625 in epoch = 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 060 train_loss: 0.1042     val_loss 0.1692 train_acc 0.9641, val_acc 0.9429,     train_f1 0.9752, val_f1 0.9611     best_val_f1 = 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  60%|██████    | 60/100 [02:08<01:25,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 60 no improvement for metric, best metric = 0.9625 in epoch = 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 061 train_loss: 0.0927     val_loss 0.1520 train_acc 0.9663, val_acc 0.9493,     train_f1 0.9767, val_f1 0.9651     best_val_f1 = 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 062 train_loss: 0.0987     val_loss 0.1718 train_acc 0.9655, val_acc 0.9446,     train_f1 0.9762, val_f1 0.9617     best_val_f1 = 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  62%|██████▏   | 62/100 [02:12<01:21,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 62 no improvement for metric, best metric = 0.9651 in epoch = 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 063 train_loss: 0.0951     val_loss 0.1394 train_acc 0.9654, val_acc 0.9519,     train_f1 0.9761, val_f1 0.9665     best_val_f1 = 0.9665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 064 train_loss: 0.0883     val_loss 0.1607 train_acc 0.9682, val_acc 0.9468,     train_f1 0.9780, val_f1 0.9631     best_val_f1 = 0.9665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  64%|██████▍   | 64/100 [02:16<01:17,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 64 no improvement for metric, best metric = 0.9665 in epoch = 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 065 train_loss: 0.0920     val_loss 0.1482 train_acc 0.9661, val_acc 0.9493,     train_f1 0.9765, val_f1 0.9650     best_val_f1 = 0.9665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  65%|██████▌   | 65/100 [02:18<01:15,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping: current epoch 65 no improvement for metric, best metric = 0.9665 in epoch = 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  65%|██████▌   | 65/100 [02:20<01:15,  2.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_t, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, model, epochs, criterion, opt, scheduler, early_stopping)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mepochs) \u001b[38;5;28;01mas\u001b[39;00m pbar_outer:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 19\u001b[0m         train_loss, train_acc, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mfit_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         val_loss, val_acc, val_f1 \u001b[38;5;241m=\u001b[39m eval_epoch(model, val_loader, criterion, epoch)\n\u001b[1;32m     22\u001b[0m         history\u001b[38;5;241m.\u001b[39mappend((train_loss, train_acc, train_f1, val_loss, val_acc, val_f1))\n",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m, in \u001b[0;36mfit_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, epoch_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(F\u001b[38;5;241m.\u001b[39msoftmax(outputs,\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_t, history = train(train_loader, val_loader, model_t, N_EPOCHS,\\\n",
    "                         criterion, optimizer, scheduler=None, early_stopping=early_stopping )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
