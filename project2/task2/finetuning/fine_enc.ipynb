{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    balanced_accuracy_score, \n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay, \n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from lightgbm import LGBMClassifier\n",
    "pd.set_option('display.max_columns', None)\n",
    "from torch import nn, Tensor\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from cnn_utils import (\n",
    "    PTB_Dataset,\n",
    "    EarlyStopping,\n",
    "    set_all_seeds,\n",
    "    train_and_validate,\n",
    "    test,\n",
    ")\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16808, 187) (16808,)\n",
      "(array([0., 1.]), array([8404, 8404], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#path= \"../../data\" \n",
    "path = r'C:\\Users\\pauls\\Desktop\\Studium\\Machine Learning for Health Care\\Projekt 2\\project2_TS_input'\n",
    "TEST_BATCH_SIZE = 256\n",
    "SEED = 42\n",
    "\n",
    "ptb_read_train = pd.read_csv(os.path.join(path, 'ptbdb_train.csv'), header=None)\n",
    "ptb_read_test = pd.read_csv(os.path.join(path, 'ptbdb_test.csv'), header=None)\n",
    "X_ptb_train = ptb_read_train.iloc[:, :-1].to_numpy()\n",
    "X_ptb_test = ptb_read_test.iloc[:, :-1].to_numpy()\n",
    "y_ptb_train = ptb_read_train.iloc[:, -1].to_numpy()\n",
    "y_ptb_test = ptb_read_test.iloc[:, -1].to_numpy()\n",
    "\n",
    "sm = SMOTE(random_state=SEED)\n",
    "X_ptb_train_resampled, y_ptb_train_resampled = sm.fit_resample(X_ptb_train, y_ptb_train)\n",
    "print(X_ptb_train_resampled.shape, y_ptb_train_resampled.shape)\n",
    "print(np.unique(y_ptb_train_resampled, return_counts=True))\n",
    "\n",
    "# Apply the data loader to the datasets ptb train\n",
    "ptb_loader_train = DataLoader(\n",
    "    PTB_Dataset(X_ptb_train_resampled, y_ptb_train_resampled),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Apply the data loader to the datasets ptb test\n",
    "ptb_loader_test = DataLoader(\n",
    "    PTB_Dataset(X_ptb_test, y_ptb_test),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings from the CNN encoder (Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, classes_num: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self._create_conv_block(in_channels, 32, 3, 1)\n",
    "        self.conv2 = self._create_conv_block(32, 64, 3, 1)\n",
    "        self.conv3 = self._create_conv_block(64, 128, 3, 1)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(output_size = 10)\n",
    "\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            #nn.Linear(1280, 256),\n",
    "            nn.Linear(1280, 16),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(16, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x  \n",
    "\n",
    "    def _create_conv_block(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "class ModifiedCNN(CNN):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc[0](x)\n",
    "        return x\n",
    "\n",
    "# Replace CNN with the modified version that returns the last conv layer output\n",
    "model_Q1 = ModifiedCNN(classes_num=5, in_channels=1)\n",
    "\n",
    "path_Q1 = \"../weights/cnn_mitbih.pth\"\n",
    "\n",
    "model_Q1.load_state_dict(torch.load(path_Q1,map_location=DEVICE))\n",
    "model_Q1.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain representations\n",
    "# Initialize an empty list to store the embeddings\n",
    "embeddings_ptb_train = []\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model_Q1.eval()\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_train:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q1(inputs)\n",
    "        embeddings_ptb_train.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_train_Q1 = np.concatenate(embeddings_ptb_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ptb_test = []\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_test:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q1(inputs)\n",
    "        embeddings_ptb_test.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_test_Q1 = np.concatenate(embeddings_ptb_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "emb_ptb_train_Q1 = scaler.fit_transform(emb_ptb_train_Q1)\n",
    "emb_ptb_test_Q1 = scaler.transform(emb_ptb_test_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16808, 16)\n",
      "(16808,)\n"
     ]
    }
   ],
   "source": [
    "print(emb_ptb_train_Q1.shape)\n",
    "print(y_ptb_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_no_feat_eng_Q1 =LGBMClassifier(\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=1000\n",
    ")\n",
    "boost_no_feat_eng_Q1.fit(emb_ptb_train_Q1, y_ptb_train_resampled)\n",
    "\n",
    "y_preds = boost_no_feat_eng_Q1.predict(emb_ptb_test_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24164e94c40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_ptb_test, y_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.919959\n",
      "Test balanced accuracy: 0.910741\n",
      "Test f1 score: 0.943842\n",
      "Test precision: 0.956522\n",
      "Test recall: 0.931494\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall:\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test balanced accuracy: {balanced_accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test f1 score: {f1_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test precision: {precision:.6f}\")\n",
    "print(f\"Test recall: {recall:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       809\n",
      "         1.0       0.96      0.93      0.94      2102\n",
      "\n",
      "    accuracy                           0.92      2911\n",
      "   macro avg       0.89      0.91      0.90      2911\n",
      "weighted avg       0.92      0.92      0.92      2911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_ptb_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We based our CNN on this: https://medium.com/@chen-yu/building-a-customized-residual-cnn-with-pytorch-471810e894ed\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self._create_conv_block(in_channels, 32, 3, 1)\n",
    "        self.conv2 = self._create_conv_block(32, 64, 3, 1)\n",
    "        self.conv3 = self._create_conv_block(64, 128, 3, 1)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(output_size = 10)\n",
    "        \n",
    "        \n",
    "        # Flattening and final linear layer\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.fc = nn.Linear(1280, latent_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.unsqueeze(1) # Add channel dimension\n",
    "        # now: [batch_size, in_channels, seq_len] i.e. [batch_size, 1, 187]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def _create_conv_block(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=stride, \n",
    "                padding=1, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "\n",
    "set_all_seeds(SEED)\n",
    "encoder=CNNEncoder(latent_dim=latent_dim, in_channels=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNEncoder(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2 = CNNEncoder(latent_dim=latent_dim, in_channels=1).to(DEVICE)\n",
    "model_Q2.load_state_dict(torch.load(\"../weights/encoder_q2.pth\", map_location=DEVICE))\n",
    "model_Q2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ptb_train = []\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model_Q2.eval()\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_train:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q2(inputs)\n",
    "        embeddings_ptb_train.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_train_Q2 = np.concatenate(embeddings_ptb_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ptb_test = []\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_test:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q2(inputs)\n",
    "        embeddings_ptb_test.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_test_Q2 = np.concatenate(embeddings_ptb_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"embeddings/emb_ptb_train_Q2\", emb_ptb_train_Q2)\n",
    "# np.save(\"embeddings/emb_ptb_test_Q2\", emb_ptb_test_Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ptb_train_Q2 = scaler.fit_transform(emb_ptb_train_Q2)\n",
    "emb_ptb_test_Q2 = scaler.transform(emb_ptb_test_Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_no_feat_eng_Q2 =LGBMClassifier(\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=1000\n",
    ")\n",
    "boost_no_feat_eng_Q2.fit(emb_ptb_train_Q2, y_ptb_train_resampled)\n",
    "\n",
    "y_preds = boost_no_feat_eng_Q2.predict(emb_ptb_test_Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24164eb82b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_ptb_test, y_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.955685\n",
      "Test balanced accuracy: 0.949546\n",
      "Test f1 score: 0.969131\n",
      "Test precision: 0.974964\n",
      "Test recall: 0.963368\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall:\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test balanced accuracy: {balanced_accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test f1 score: {f1_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test precision: {precision:.6f}\")\n",
    "print(f\"Test recall: {recall:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92       809\n",
      "         1.0       0.97      0.96      0.97      2102\n",
      "\n",
      "    accuracy                           0.96      2911\n",
      "   macro avg       0.94      0.95      0.95      2911\n",
      "weighted avg       0.96      0.96      0.96      2911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_ptb_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP output layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MLP layers, we'll first have to introduce a training / validation split. Note that we only apply SMOTE on the training set after the train/ validation split has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15126, 187) (15126,)\n",
      "(array([0., 1.]), array([7563, 7563], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X_ptb_train, X_ptb_val, y_ptb_train, y_ptb_val = train_test_split(\n",
    "    X_ptb_train,\n",
    "    y_ptb_train,\n",
    "    test_size=0.1, \n",
    "    stratify=y_ptb_train, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sm = SMOTE(random_state=SEED)\n",
    "X_ptb_train_resampled, y_ptb_train_resampled = sm.fit_resample(X_ptb_train, y_ptb_train)\n",
    "print(X_ptb_train_resampled.shape, y_ptb_train_resampled.shape)\n",
    "print(np.unique(y_ptb_train_resampled, return_counts=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_train_loader_resampled = DataLoader(\n",
    "    PTB_Dataset(X_ptb_train_resampled, y_ptb_train_resampled),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "ptb_val_loader = DataLoader(\n",
    "    PTB_Dataset(X_ptb_val, y_ptb_val),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "ptb_test_loader = DataLoader(\n",
    "    PTB_Dataset(X_ptb_test, y_ptb_test),\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all_but_MLP(model: nn.Module):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_encoder(model: nn.Module):\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the output layer(s) only on the PTB dataset, freezing the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q1_Model(nn.Module):\n",
    "    def __init__(self, classes_num: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = ModifiedCNN(classes_num=5, in_channels=in_channels) # num_classes doesn't matter here; only needed to load encoder correctly\n",
    "        self.encoder.load_state_dict(torch.load(\"../weights/cnn_mitbih.pth\", map_location=DEVICE))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Replace CNN with the modified version that returns the last conv layer output\n",
    "model_Q1_A = Q1_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\miniconda3\\envs\\introtoml\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_Q1_A = model_Q1_A.to(DEVICE)\n",
    "\n",
    "freeze_all_but_MLP(model_Q1_A)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q1_A.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.5, patience=5, threshold=1e-06, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "Training CNN:  87%| | 87/100 [00:55<00:08,  1.58it/s, train_balanced_acc=0.938, train_loss=0.00473, val_balanced_acc=0.908, val_loss=0.00739]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 87. Best score was 0.9177 in epoch 67.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "model_Q1_A = train_and_validate(\n",
    "    model = model_Q1_A,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_A.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Model(\n",
       "  (encoder): ModifiedCNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q1_A.load_state_dict(torch.load(\"../weights/cnn_Q1_A.pth\",map_location=DEVICE))\n",
    "model_Q1_A.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0009, Test accuracy: 0.9148, Test balanced accuracy: 0.9152, Test F1 score: 0.9394\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q1_A,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.885\n",
      "Test recall: 0.915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test precision: {precision_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")\n",
    "print(f\"Test recall: {recall_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Train the entire model on the PTB dataset (encoder + output layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace CNN with the modified version that returns the last conv layer output\n",
    "model_Q1_B = Q1_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\miniconda3\\envs\\introtoml\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_Q1_B = model_Q1_B.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q1_B.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.5, patience=5, threshold=1e-06, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training CNN:  64%|   | 64/100 [01:01<00:34,  1.05it/s, train_balanced_acc=1, train_loss=2.09e-6, val_balanced_acc=0.987, val_loss=0.00349]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 64. Best score was 0.9901 in epoch 44.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "model_Q1_B = train_and_validate(\n",
    "    model = model_Q1_B,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_B.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Model(\n",
       "  (encoder): ModifiedCNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q1_B.load_state_dict(torch.load(\"../weights/cnn_Q1_B.pth\",map_location=DEVICE))\n",
    "model_Q1_B.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0006, Test accuracy: 0.9890, Test balanced accuracy: 0.9852, Test F1 score: 0.9924\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q1_B,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.987\n",
      "Test recall: 0.985\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test precision: {precision_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")\n",
    "print(f\"Test recall: {recall_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q1_C = Q1_Model(classes_num=2, in_channels=1)\n",
    "model_Q1_C = model_Q1_C.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train the output layers for a low number of epochs for the output layers to adapt to the PTB dataset. Then, we unfreeze the encoder and train the entire model for a higher number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_all_but_MLP(model_Q1_C)\n",
    "optimizer = optim.AdamW(model_Q1_C.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q1_C = train_and_validate(\n",
    "    model = model_Q1_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = 15,\n",
    "    ES = None # no early stopping, train for full 10 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the entire model on the PTB dataset for a higher number of epochs and with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_encoder(model_Q1_C)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q1_C.parameters(), lr=0.00005, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  88%| | 88/100 [01:22<00:11,  1.07it/s, train_balanced_acc=0.994, train_loss=0.000508, val_balanced_acc=0.977, val_loss=0.00292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 88. Best score was 0.9799 in epoch 68.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")\n",
    "\n",
    "\n",
    "model_Q1_C = train_and_validate(\n",
    "    model = model_Q1_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Model(\n",
       "  (encoder): ModifiedCNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q1_C.load_state_dict(torch.load(\"../weights/cnn_Q1_C.pth\",map_location=DEVICE))\n",
    "model_Q1_C.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0004, Test accuracy: 0.9794, Test balanced accuracy: 0.9755, Test F1 score: 0.9857\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q1_C,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.973\n",
      "Test recall: 0.975\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test precision: {precision_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")\n",
    "print(f\"Test recall: {recall_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the output layer(s) only on the PTB dataset, freezing the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We slightly modify the CCNEncoder function from the representation_learning.ipynb file by also adding output layers onto it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q2_Model(nn.Module):\n",
    "    def __init__(self, classes_num: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = CNNEncoder(latent_dim=16, in_channels=in_channels).to(DEVICE)\n",
    "        self.encoder.load_state_dict(torch.load(\"../weights/encoder_q2.pth\", map_location=DEVICE))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "#encoder=CNNEncoder(latent_dim=latent_dim, in_channels=1).to(DEVICE)\n",
    "\n",
    "model_Q2_A = Q2_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\miniconda3\\envs\\introtoml\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_Q2_A = model_Q2_A.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q2_A.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.5, patience=5, threshold=1e-06, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  68%|   | 68/100 [00:43<00:20,  1.55it/s, train_balanced_acc=0.957, train_loss=0.00355, val_balanced_acc=0.95, val_loss=0.00461] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 68. Best score was 0.9553 in epoch 48.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "freeze_all_but_MLP(model_Q2_A)\n",
    "\n",
    "model_Q2_A = train_and_validate(\n",
    "    model = model_Q2_A,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q2_A.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q2_Model(\n",
       "  (encoder): CNNEncoder(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2_A.load_state_dict(torch.load(\"../weights/cnn_Q2_A.pth\",map_location=DEVICE))\n",
    "model_Q2_A.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0005, Test accuracy: 0.9581, Test balanced accuracy: 0.9573, Test F1 score: 0.9706\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q2_A,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.941\n",
      "Test recall: 0.957\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test precision: {precision_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")\n",
    "print(f\"Test recall: {recall_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Train the entire model on the PTB dataset (encoder + output layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q2_B = Q2_Model(classes_num=2, in_channels=1)\n",
    "model_Q2_B = model_Q2_B.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q2_B.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  46%|     | 46/100 [00:42<00:49,  1.08it/s, train_balanced_acc=0.998, train_loss=0.000192, val_balanced_acc=0.978, val_loss=0.00256] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 46. Best score was 0.9936 in epoch 26.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "model_Q2_B = train_and_validate(\n",
    "    model = model_Q2_B,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q2_B.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q2_Model(\n",
       "  (encoder): CNNEncoder(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2_B.load_state_dict(torch.load(\"../weights/cnn_Q2_B.pth\",map_location=DEVICE))\n",
    "model_Q2_B.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0004, Test accuracy: 0.9959, Test balanced accuracy: 0.9941, Test F1 score: 0.9971\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q2_B,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.996\n",
      "Test recall: 0.994\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test precision: {precision_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")\n",
    "print(f\"Test recall: {recall_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q2_C = Q2_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we first train the output layers for a low number of epochs for the output layers to adapt to the PTB dataset. Then, we unfreeze the encoder and train the entire model for a higher number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q2_C = model_Q2_C.to(DEVICE)\n",
    "freeze_all_but_MLP(model_Q2_C)\n",
    "optimizer = optim.AdamW(model_Q2_C.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN: 100%|| 15/15 [00:09<00:00,  1.63it/s, train_balanced_acc=0.926, train_loss=0.0058, val_balanced_acc=0.941, val_loss=0.00537] \n"
     ]
    }
   ],
   "source": [
    "model_Q2_C = train_and_validate(\n",
    "    model = model_Q2_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = 15,\n",
    "    ES = None # no early stopping, train for full 10 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the entire model on the PTB dataset for a higher number of epochs and with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")\n",
    "#Note: We lowered the learning rate here\n",
    "optimizer = optim.AdamW(model_Q2_C.parameters(), lr=0.00005, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  69%|   | 69/100 [01:04<00:28,  1.08it/s, train_balanced_acc=0.998, train_loss=0.000229, val_balanced_acc=0.989, val_loss=0.00146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 69. Best score was 0.9911 in epoch 49.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "unfreeze_encoder(model_Q2_C)\n",
    "\n",
    "model_Q2_C = train_and_validate(\n",
    "    model = model_Q2_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q2_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q2_Model(\n",
       "  (encoder): CNNEncoder(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2_C.load_state_dict(torch.load(\"../weights/cnn_Q2_C.pth\",map_location=DEVICE))\n",
    "model_Q2_C.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0002, Test accuracy: 0.9924, Test balanced accuracy: 0.9898, Test F1 score: 0.9948\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q2_C,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.991\n",
      "Test recall: 0.990\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test precision: {precision_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")\n",
    "print(f\"Test recall: {recall_score(y_ptb_test, y_preds, average = 'macro'):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
