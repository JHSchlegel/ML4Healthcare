{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    balanced_accuracy_score, \n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay, \n",
    "    accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from lightgbm import LGBMClassifier\n",
    "pd.set_option('display.max_columns', None)\n",
    "from torch import nn, Tensor\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from cnn_utils import (\n",
    "    PTB_Dataset,\n",
    "    EarlyStopping,\n",
    "    set_all_seeds,\n",
    "    train_and_validate,\n",
    "    test,\n",
    ")\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16808, 187) (16808,)\n",
      "(array([0., 1.]), array([8404, 8404]))\n"
     ]
    }
   ],
   "source": [
    "path= \"../../data\" #r'C:\\Users\\pauls\\Desktop\\Studium\\Machine Learning for Health Care\\Projekt 2\\project2_TS_input'\n",
    "#path = \"../../data\"\n",
    "TEST_BATCH_SIZE = 256\n",
    "SEED = 42\n",
    "\n",
    "ptb_read_train = pd.read_csv(os.path.join(path, 'ptbdb_train.csv'), header=None)\n",
    "ptb_read_test = pd.read_csv(os.path.join(path, 'ptbdb_test.csv'), header=None)\n",
    "X_ptb_train = ptb_read_train.iloc[:, :-1].to_numpy()\n",
    "X_ptb_test = ptb_read_test.iloc[:, :-1].to_numpy()\n",
    "y_ptb_train = ptb_read_train.iloc[:, -1].to_numpy()\n",
    "y_ptb_test = ptb_read_test.iloc[:, -1].to_numpy()\n",
    "\n",
    "sm = SMOTE(random_state=SEED)\n",
    "X_ptb_train_resampled, y_ptb_train_resampled = sm.fit_resample(X_ptb_train, y_ptb_train)\n",
    "print(X_ptb_train_resampled.shape, y_ptb_train_resampled.shape)\n",
    "print(np.unique(y_ptb_train_resampled, return_counts=True))\n",
    "\n",
    "# Apply the data loader to the datasets ptb train\n",
    "ptb_loader_train = DataLoader(\n",
    "    PTB_Dataset(X_ptb_train_resampled, y_ptb_train_resampled),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Apply the data loader to the datasets ptb test\n",
    "ptb_loader_test = DataLoader(\n",
    "    PTB_Dataset(X_ptb_test, y_ptb_test),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings from the CNN encoder (Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, classes_num: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self._create_conv_block(in_channels, 32, 3, 1)\n",
    "        self.conv2 = self._create_conv_block(32, 64, 3, 1)\n",
    "        self.conv3 = self._create_conv_block(64, 128, 3, 1)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(output_size = 10)\n",
    "\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            #nn.Linear(1280, 256),\n",
    "            nn.Linear(1280, 16),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(16, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x  \n",
    "\n",
    "    def _create_conv_block(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "class ModifiedCNN(CNN):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc[0](x)\n",
    "        return x\n",
    "\n",
    "# Replace CNN with the modified version that returns the last conv layer output\n",
    "model_Q1 = ModifiedCNN(classes_num=5, in_channels=1)\n",
    "\n",
    "path_Q1 = \"../weights/cnn_mitbih.pth\"\n",
    "\n",
    "model_Q1.load_state_dict(torch.load(path_Q1,map_location=DEVICE))\n",
    "model_Q1.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "# Obtain representations\n",
    "# Initialize an empty list to store the embeddings\n",
    "embeddings_ptb_train = []\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model_Q1.eval()\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_train:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q1(inputs)\n",
    "        embeddings_ptb_train.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_train_Q1 = np.concatenate(embeddings_ptb_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ptb_test = []\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_test:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q1(inputs)\n",
    "        embeddings_ptb_test.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_test_Q1 = np.concatenate(embeddings_ptb_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "emb_ptb_train_Q1 = scaler.fit_transform(emb_ptb_train_Q1)\n",
    "emb_ptb_test_Q1 = scaler.transform(emb_ptb_test_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16808, 16)\n",
      "(16808,)\n"
     ]
    }
   ],
   "source": [
    "print(emb_ptb_train_Q1.shape)\n",
    "print(y_ptb_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_no_feat_eng_Q1 =LGBMClassifier(\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=1000\n",
    ")\n",
    "boost_no_feat_eng_Q1.fit(emb_ptb_train_Q1, y_ptb_train_resampled)\n",
    "\n",
    "y_preds = boost_no_feat_eng_Q1.predict(emb_ptb_test_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7efe540a6e60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_ptb_test, y_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.918585\n",
      "Test balanced accuracy: 0.908649\n",
      "Test f1 score: 0.942905\n",
      "Test precision: 0.955100\n",
      "Test recall: 0.931018\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall:\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test balanced accuracy: {balanced_accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test f1 score: {f1_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test precision: {precision:.6f}\")\n",
    "print(f\"Test recall: {recall:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       809\n",
      "         1.0       0.96      0.93      0.94      2102\n",
      "\n",
      "    accuracy                           0.92      2911\n",
      "   macro avg       0.89      0.91      0.90      2911\n",
      "weighted avg       0.92      0.92      0.92      2911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_ptb_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We based our CNN on this: https://medium.com/@chen-yu/building-a-customized-residual-cnn-with-pytorch-471810e894ed\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self._create_conv_block(in_channels, 32, 3, 1)\n",
    "        self.conv2 = self._create_conv_block(32, 64, 3, 1)\n",
    "        self.conv3 = self._create_conv_block(64, 128, 3, 1)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(output_size = 10)\n",
    "        \n",
    "        \n",
    "        # Flattening and final linear layer\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.fc = nn.Linear(1280, latent_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.unsqueeze(1) # Add channel dimension\n",
    "        # now: [batch_size, in_channels, seq_len] i.e. [batch_size, 1, 187]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def _create_conv_block(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=stride, \n",
    "                padding=1, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "\n",
    "set_all_seeds(SEED)\n",
    "encoder=CNNEncoder(latent_dim=latent_dim, in_channels=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNEncoder(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2 = CNNEncoder(latent_dim=latent_dim, in_channels=1).to(DEVICE)\n",
    "model_Q2.load_state_dict(torch.load(\"../weights/encoder_q2.pth\", map_location=DEVICE))\n",
    "model_Q2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "embeddings_ptb_train = []\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model_Q2.eval()\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_train:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q2(inputs)\n",
    "        embeddings_ptb_train.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_train_Q2 = np.concatenate(embeddings_ptb_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ptb_test = []\n",
    "\n",
    "# No need to track gradients for this\n",
    "with torch.no_grad():\n",
    "    # Iterate over the dataset\n",
    "    for inputs, _ in ptb_loader_test:\n",
    "        # Move the inputs to the same device as the model\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        # Get the embeddings for this batch and append to the list\n",
    "        embedding = model_Q2(inputs)\n",
    "        embeddings_ptb_test.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single numpy array\n",
    "emb_ptb_test_Q2 = np.concatenate(embeddings_ptb_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"embeddings/emb_ptb_train_Q2\", emb_ptb_train_Q2)\n",
    "# np.save(\"embeddings/emb_ptb_test_Q2\", emb_ptb_test_Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ptb_train_Q2 = scaler.fit_transform(emb_ptb_train_Q2)\n",
    "emb_ptb_test_Q2 = scaler.transform(emb_ptb_test_Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_no_feat_eng_Q2 =LGBMClassifier(\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=1000\n",
    ")\n",
    "boost_no_feat_eng_Q2.fit(emb_ptb_train_Q2, y_ptb_train_resampled)\n",
    "\n",
    "y_preds = boost_no_feat_eng_Q2.predict(emb_ptb_test_Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7efe566f98d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_ptb_test, y_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.954998\n",
      "Test balanced accuracy: 0.948310\n",
      "Test f1 score: 0.968668\n",
      "Test precision: 0.974026\n",
      "Test recall: 0.963368\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall:\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test balanced accuracy: {balanced_accuracy_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test f1 score: {f1_score(y_ptb_test, y_preds):.6f}\")\n",
    "print(f\"Test precision: {precision:.6f}\")\n",
    "print(f\"Test recall: {recall:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.93      0.92       809\n",
      "         1.0       0.97      0.96      0.97      2102\n",
      "\n",
      "    accuracy                           0.95      2911\n",
      "   macro avg       0.94      0.95      0.94      2911\n",
      "weighted avg       0.96      0.95      0.96      2911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_ptb_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP output layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MLP layers, we'll first have to introduce a training / validation split. Note that we only apply SMOTE on the training set after the train/ validation split has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15126, 187) (15126,)\n",
      "(array([0., 1.]), array([7563, 7563]))\n"
     ]
    }
   ],
   "source": [
    "X_ptb_train, X_ptb_val, y_ptb_train, y_ptb_val = train_test_split(\n",
    "    X_ptb_train,\n",
    "    y_ptb_train,\n",
    "    test_size=0.1, \n",
    "    stratify=y_ptb_train, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sm = SMOTE(random_state=SEED)\n",
    "X_ptb_train_resampled, y_ptb_train_resampled = sm.fit_resample(X_ptb_train, y_ptb_train)\n",
    "print(X_ptb_train_resampled.shape, y_ptb_train_resampled.shape)\n",
    "print(np.unique(y_ptb_train_resampled, return_counts=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like before the Dataloader got the embeddings as the intput. I will have to think about how to go about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_train_loader_resampled = DataLoader(\n",
    "    PTB_Dataset(X_ptb_train_resampled, y_ptb_train_resampled),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "ptb_val_loader = DataLoader(\n",
    "    PTB_Dataset(X_ptb_val, y_ptb_val),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "ptb_test_loader = DataLoader(\n",
    "    PTB_Dataset(X_ptb_test, y_ptb_test),\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all_but_MLP(model: nn.Module):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_encoder(model: nn.Module):\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the output layer(s) only on the PTB dataset, freezing the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q1_Model(nn.Module):\n",
    "    def __init__(self, classes_num: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = ModifiedCNN(classes_num=5, in_channels=in_channels) # num_classes doesn't matter here; only needed to load encoder correctly\n",
    "        self.encoder.load_state_dict(torch.load(\"../weights/cnn_mitbih.pth\", map_location=DEVICE))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Replace CNN with the modified version that returns the last conv layer output\n",
    "model_Q1_A = Q1_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_Q1_A = model_Q1_A.to(DEVICE)\n",
    "\n",
    "freeze_all_but_MLP(model_Q1_A)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q1_A.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.5, patience=5, threshold=1e-06, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "Training CNN:  87%| | 87/100 [00:55<00:08,  1.58it/s, train_balanced_acc=0.938, train_loss=0.00473, val_balanced_acc=0.908, val_loss=0.00739]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 87. Best score was 0.9177 in epoch 67.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "model_Q1_A = train_and_validate(\n",
    "    model = model_Q1_A,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_A.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Model(\n",
       "  (encoder): ModifiedCNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q1_A.load_state_dict(torch.load(\"../weights/cnn_Q1_A.pth\",map_location=DEVICE))\n",
    "model_Q1_A.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0009, Test accuracy: 0.9148, Test balanced accuracy: 0.9152, Test F1 score: 0.9394\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q1_A,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Train the entire model on the PTB dataset (encoder + output layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace CNN with the modified version that returns the last conv layer output\n",
    "model_Q1_B = Q1_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_Q1_B = model_Q1_B.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q1_B.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.5, patience=5, threshold=1e-06, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training CNN:  64%|   | 64/100 [01:01<00:34,  1.05it/s, train_balanced_acc=1, train_loss=2.09e-6, val_balanced_acc=0.987, val_loss=0.00349]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 64. Best score was 0.9901 in epoch 44.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "model_Q1_B = train_and_validate(\n",
    "    model = model_Q1_B,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_B.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Model(\n",
       "  (encoder): ModifiedCNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q1_B.load_state_dict(torch.load(\"../weights/cnn_Q1_B.pth\",map_location=DEVICE))\n",
    "model_Q1_B.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0006, Test accuracy: 0.9890, Test balanced accuracy: 0.9852, Test F1 score: 0.9924\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q1_B,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q1_C = Q1_Model(classes_num=2, in_channels=1)\n",
    "model_Q1_C = model_Q1_C.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train the output layers for a low number of epochs for the output layers to adapt to the PTB dataset. Then, we unfreeze the encoder and train the entire model for a higher number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_all_but_MLP(model_Q1_C)\n",
    "optimizer = optim.AdamW(model_Q1_C.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN: 100%|| 15/15 [00:09<00:00,  1.62it/s, train_balanced_acc=0.894, train_loss=0.00774, val_balanced_acc=0.892, val_loss=0.00918]\n"
     ]
    }
   ],
   "source": [
    "model_Q1_C = train_and_validate(\n",
    "    model = model_Q1_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = 15,\n",
    "    ES = None # no early stopping, train for full 10 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the entire model on the PTB dataset for a higher number of epochs and with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_encoder(model_Q1_C)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q1_C.parameters(), lr=0.00005, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  88%| | 88/100 [01:22<00:11,  1.07it/s, train_balanced_acc=0.994, train_loss=0.000508, val_balanced_acc=0.977, val_loss=0.00292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 88. Best score was 0.9799 in epoch 68.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")\n",
    "\n",
    "\n",
    "model_Q1_C = train_and_validate(\n",
    "    model = model_Q1_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Model(\n",
       "  (encoder): ModifiedCNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=16, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=16, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q1_C.load_state_dict(torch.load(\"../weights/cnn_Q1_C.pth\",map_location=DEVICE))\n",
    "model_Q1_C.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0004, Test accuracy: 0.9794, Test balanced accuracy: 0.9755, Test F1 score: 0.9857\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q1_C,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the output layer(s) only on the PTB dataset, freezing the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We slightly modify the CCNEncoder function from the representation_learning.ipynb file by also adding output layers onto it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q2_Model(nn.Module):\n",
    "    def __init__(self, classes_num: int, in_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = CNNEncoder(latent_dim=16, in_channels=in_channels).to(DEVICE)\n",
    "        self.encoder.load_state_dict(torch.load(\"../weights/encoder_q2.pth\", map_location=DEVICE))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "#encoder=CNNEncoder(latent_dim=latent_dim, in_channels=1).to(DEVICE)\n",
    "\n",
    "model_Q2_A = Q2_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/ml4hc/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_Q2_A = model_Q2_A.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q2_A.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.5, patience=5, threshold=1e-06, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  68%|   | 68/100 [00:43<00:20,  1.55it/s, train_balanced_acc=0.957, train_loss=0.00355, val_balanced_acc=0.95, val_loss=0.00461] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 68. Best score was 0.9553 in epoch 48.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "freeze_all_but_MLP(model_Q2_A)\n",
    "\n",
    "model_Q2_A = train_and_validate(\n",
    "    model = model_Q2_A,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q2_A.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q2_Model(\n",
       "  (encoder): CNNEncoder(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2_A.load_state_dict(torch.load(\"../weights/cnn_Q2_A.pth\",map_location=DEVICE))\n",
    "model_Q2_A.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0005, Test accuracy: 0.9581, Test balanced accuracy: 0.9573, Test F1 score: 0.9706\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q2_A,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Train the entire model on the PTB dataset (encoder + output layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q2_B = Q2_Model(classes_num=2, in_channels=1)\n",
    "model_Q2_B = model_Q2_B.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model_Q2_B.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  46%|     | 46/100 [00:42<00:49,  1.08it/s, train_balanced_acc=0.998, train_loss=0.000192, val_balanced_acc=0.978, val_loss=0.00256] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 46. Best score was 0.9936 in epoch 26.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "model_Q2_B = train_and_validate(\n",
    "    model = model_Q2_B,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q2_B.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q2_Model(\n",
       "  (encoder): CNNEncoder(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2_B.load_state_dict(torch.load(\"../weights/cnn_Q2_B.pth\",map_location=DEVICE))\n",
    "model_Q2_B.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0004, Test accuracy: 0.9959, Test balanced accuracy: 0.9941, Test F1 score: 0.9971\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q2_B,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. First, train the output layers, then unfreeze and train the entire joint model in two separate stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q2_C = Q2_Model(classes_num=2, in_channels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we first train the output layers for a low number of epochs for the output layers to adapt to the PTB dataset. Then, we unfreeze the encoder and train the entire model for a higher number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Q2_C = model_Q2_C.to(DEVICE)\n",
    "freeze_all_but_MLP(model_Q2_C)\n",
    "optimizer = optim.AdamW(model_Q2_C.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN: 100%|| 15/15 [00:09<00:00,  1.63it/s, train_balanced_acc=0.926, train_loss=0.0058, val_balanced_acc=0.941, val_loss=0.00537] \n"
     ]
    }
   ],
   "source": [
    "model_Q2_C = train_and_validate(\n",
    "    model = model_Q2_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q1_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = 15,\n",
    "    ES = None # no early stopping, train for full 10 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the entire model on the PTB dataset for a higher number of epochs and with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(start=20, patience=20, verbose=1, mode=\"max\")\n",
    "#Note: We lowered the learning rate here\n",
    "optimizer = optim.AdamW(model_Q2_C.parameters(), lr=0.00005, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CNN:  69%|   | 69/100 [01:04<00:28,  1.08it/s, train_balanced_acc=0.998, train_loss=0.000229, val_balanced_acc=0.989, val_loss=0.00146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 69. Best score was 0.9911 in epoch 49.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=100\n",
    "\n",
    "unfreeze_encoder(model_Q2_C)\n",
    "\n",
    "model_Q2_C = train_and_validate(\n",
    "    model = model_Q2_C,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion = criterion,\n",
    "    train_loader = ptb_train_loader_resampled,\n",
    "    val_loader = ptb_val_loader,\n",
    "    best_model_path = \"../weights/cnn_Q2_C.pth\", #os.path.join(path, \"cnn_best_model_MIT_random.pth\"),\n",
    "    device = DEVICE,\n",
    "    num_epochs = N_EPOCHS,\n",
    "    ES = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q2_Model(\n",
       "  (encoder): CNNEncoder(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (adaptive_pool): AdaptiveAvgPool1d(output_size=10)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=1280, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Q2_C.load_state_dict(torch.load(\"../weights/cnn_Q2_C.pth\",map_location=DEVICE))\n",
    "model_Q2_C.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0002, Test accuracy: 0.9924, Test balanced accuracy: 0.9898, Test F1 score: 0.9948\n"
     ]
    }
   ],
   "source": [
    "model_probs, y_preds, y_true, test_loss = test(\n",
    "    model = model_Q2_C,\n",
    "    criterion = criterion,\n",
    "    test_loader = ptb_loader_test,\n",
    "    device = DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
